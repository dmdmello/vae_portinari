{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "from skimage import io, transform\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import save_image\n",
    "from skimage.io import imread\n",
    "from torchsummary import summary\n",
    "import pandas as pd\n",
    "import time\n",
    "from models import *\n",
    "NAME = 'KL0005_64_model_novo'\n",
    "KL_PAR = 0.0005\n",
    "\n",
    "TRAIN_ROOT = '../data/data-celeba/Train'\n",
    "VAL_ROOT = '../data/data-celeba/Validation'\n",
    "VAL_ROOT_FIX = '../data/data-celeba/Fix_sample'\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 10\n",
    "LOG_INTERVAL = 50\n",
    "BOTTLENECK_SIZE = 512\n",
    "SAVE_MODEL = '../models/' + NAME\n",
    "SAVE_RESULTS = '../results/' + NAME\n",
    "%mkdir {SAVE_RESULTS}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_cuda = False\n",
    "seed = 1\n",
    "cuda = not no_cuda and torch.cuda.is_available()\n",
    "torch.manual_seed(seed)\n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if cuda else {}\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "\n",
    "transform_seq = [ transforms.Resize((200,163)), transforms.Pad(( 19, 0, 18, 0)),\n",
    "                  transforms.ToTensor(), transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))]\n",
    "\n",
    "train_loader_celeba = torch.utils.data.DataLoader(\n",
    "    datasets.ImageFolder(TRAIN_ROOT, transform=transforms.Compose(transform_seq)),\n",
    "    batch_size = BATCH_SIZE, shuffle=True, **kwargs)\n",
    "\n",
    "val_loader_celeba = torch.utils.data.DataLoader(\n",
    "    datasets.ImageFolder(VAL_ROOT, transform=transforms.Compose(transform_seq)),\n",
    "    batch_size = BATCH_SIZE, shuffle=True, **kwargs)\n",
    "\n",
    "val_loader_celeba_fix = torch.utils.data.DataLoader(\n",
    "    datasets.ImageFolder(VAL_ROOT_FIX, transform=transforms.Compose(transform_seq)),\n",
    "    batch_size = BATCH_SIZE, shuffle=False, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class customLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(customLoss, self).__init__()\n",
    "        self.mse_loss = nn.MSELoss(reduction=\"mean\")\n",
    "\n",
    "    def forward(self, x_recon, x, mu, logvar):\n",
    "        loss_MSE = self.mse_loss(x_recon, x)\n",
    "        loss_KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp(), dim = -1)\n",
    "        loss_KLD = torch.sum(loss_KLD*KL_PAR)/BATCH_SIZE\n",
    "        return loss_MSE, loss_KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE_CNN(BOTTLENECK_SIZE).to(device)\n",
    "optimizer = optim.RMSprop(model.parameters(), lr=0.001, alpha= 0.9)\n",
    "loss_custom = customLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VAE_CNN(\n",
       "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn1): BatchNorm2d(32, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "  (mxp1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn2): BatchNorm2d(64, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "  (mxp2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn3): BatchNorm2d(128, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "  (mxp3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn4): BatchNorm2d(256, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "  (mxp4): MaxPool2d(kernel_size=2, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=43264, out_features=512, bias=True)\n",
       "  (fc_bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc2): Linear(in_features=43264, out_features=512, bias=True)\n",
       "  (fc_bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc3): Linear(in_features=512, out_features=43264, bias=True)\n",
       "  (ups5): Upsample(scale_factor=2.0, mode=nearest)\n",
       "  (conv5): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn5): BatchNorm2d(256, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "  (ups6): Upsample(scale_factor=2.0, mode=nearest)\n",
       "  (conv6): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn6): BatchNorm2d(128, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "  (ups7): Upsample(scale_factor=2.0, mode=nearest)\n",
       "  (conv7): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn7): BatchNorm2d(64, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "  (ups8): Upsample(scale_factor=2.0, mode=nearest)\n",
       "  (conv8): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn8): BatchNorm2d(32, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "  (conv9): ConvTranspose2d(32, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu): ReLU()\n",
       "  (tanh): Tanh()\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#summary(model, (3,200,200))\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_losses = []\n",
    "train_losses = []\n",
    "\n",
    "def train(epoch):\n",
    "    epoch_start = 0\n",
    "    model.train(True)\n",
    "    train_loss = 0\n",
    "    start = time.time()\n",
    "    for batch_idx, (data, _) in enumerate(train_loader_celeba): \n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = model(data)\n",
    "        loss_mse, loss_kl = loss_custom(recon_batch, data, mu, logvar)\n",
    "        loss = loss_mse + loss_kl\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        if batch_idx % LOG_INTERVAL == 0:\n",
    "            interval = time.time() - start\n",
    "            start = time.time()\n",
    "            epoch_start = epoch_start + interval\n",
    "            \n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss MSE: {:.6f} \\tLoss KL: {:.6f} \\tTime Interv: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader_celeba.dataset),\n",
    "                       100. * batch_idx / len(train_loader_celeba),\n",
    "                       loss_mse.item(), loss_kl.item(), interval))\n",
    "\n",
    "    print('====> Epoch: {} Average loss: {:.6f} Elapsed Time: {:.6f}'.format(\n",
    "        epoch, train_loss * BATCH_SIZE / len(train_loader_celeba.dataset), epoch_start))\n",
    "    train_losses.append(train_loss*BATCH_SIZE/ len(train_loader_celeba.dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch, sufix, train):\n",
    "    model.train(train)\n",
    "    test_loss_mse = 0\n",
    "    test_loss_kl = 0\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for i, (data, _) in enumerate(val_loader_celeba):\n",
    "            data = data.to(device)\n",
    "            recon_batch, mu, logvar = model(data)\n",
    "            loss_mse, loss_kl = loss_custom(recon_batch, data, mu, logvar)\n",
    "            loss = loss_mse + loss_kl\n",
    "            test_loss_mse += loss_mse.item()\n",
    "            test_loss_kl += loss_kl.item()\n",
    "            \n",
    "        for i, (data, _) in enumerate(val_loader_celeba_fix):\n",
    "            data = data.to(device)\n",
    "            recon_batch, mu, logvar = model(data)\n",
    "            if i == 0:\n",
    "                n = min(data.size(0), 8)\n",
    "                comparison = torch.cat([data[:n],\n",
    "                                        recon_batch.view(7, 3, 200, 200)[:n]])\n",
    "                save_image(comparison.cpu(),\n",
    "                           SAVE_RESULTS + '/reconstruction_' + str(epoch) + sufix + '.png', nrow=n, normalize=True)\n",
    "\n",
    "    test_loss_mse = test_loss_mse * BATCH_SIZE / len(val_loader_celeba.dataset)\n",
    "    test_loss_kl = test_loss_kl * BATCH_SIZE / len(val_loader_celeba.dataset)\n",
    "    print('====> Test set loss-mse: {:.6f}, loss-kl: {:.6f}'.format(test_loss_mse, test_loss_kl))\n",
    "    val_losses.append((test_loss_mse, test_loss_kl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40520"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_loader_celeba.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/162078 (0%)]\tLoss MSE: 1.156556 \tLoss KL: 0.212160 \tTime Interv: 1.544275\n",
      "Train Epoch: 1 [3200/162078 (2%)]\tLoss MSE: 0.170148 \tLoss KL: 0.153510 \tTime Interv: 19.112265\n",
      "Train Epoch: 1 [6400/162078 (4%)]\tLoss MSE: 0.122772 \tLoss KL: 0.138560 \tTime Interv: 19.084737\n",
      "Train Epoch: 1 [9600/162078 (6%)]\tLoss MSE: 0.098175 \tLoss KL: 0.114333 \tTime Interv: 19.100178\n",
      "Train Epoch: 1 [12800/162078 (8%)]\tLoss MSE: 0.084983 \tLoss KL: 0.102693 \tTime Interv: 19.118302\n",
      "Train Epoch: 1 [16000/162078 (10%)]\tLoss MSE: 0.080140 \tLoss KL: 0.091662 \tTime Interv: 19.118881\n",
      "Train Epoch: 1 [19200/162078 (12%)]\tLoss MSE: 0.076502 \tLoss KL: 0.079524 \tTime Interv: 19.158254\n",
      "Train Epoch: 1 [22400/162078 (14%)]\tLoss MSE: 0.088202 \tLoss KL: 0.069466 \tTime Interv: 19.165488\n",
      "Train Epoch: 1 [25600/162078 (16%)]\tLoss MSE: 0.077042 \tLoss KL: 0.060393 \tTime Interv: 19.166952\n",
      "Train Epoch: 1 [28800/162078 (18%)]\tLoss MSE: 0.076774 \tLoss KL: 0.053049 \tTime Interv: 19.174534\n",
      "Train Epoch: 1 [32000/162078 (20%)]\tLoss MSE: 0.073574 \tLoss KL: 0.047174 \tTime Interv: 19.162163\n",
      "Train Epoch: 1 [35200/162078 (22%)]\tLoss MSE: 0.080197 \tLoss KL: 0.040658 \tTime Interv: 19.189146\n",
      "Train Epoch: 1 [38400/162078 (24%)]\tLoss MSE: 0.079220 \tLoss KL: 0.035569 \tTime Interv: 19.172138\n",
      "Train Epoch: 1 [41600/162078 (26%)]\tLoss MSE: 0.079819 \tLoss KL: 0.032682 \tTime Interv: 19.142520\n",
      "Train Epoch: 1 [44800/162078 (28%)]\tLoss MSE: 0.086987 \tLoss KL: 0.031234 \tTime Interv: 19.141756\n",
      "Train Epoch: 1 [48000/162078 (30%)]\tLoss MSE: 0.082396 \tLoss KL: 0.029391 \tTime Interv: 19.144348\n",
      "Train Epoch: 1 [51200/162078 (32%)]\tLoss MSE: 0.088144 \tLoss KL: 0.028522 \tTime Interv: 19.142884\n",
      "Train Epoch: 1 [54400/162078 (34%)]\tLoss MSE: 0.082868 \tLoss KL: 0.028265 \tTime Interv: 19.173722\n",
      "Train Epoch: 1 [57600/162078 (36%)]\tLoss MSE: 0.083045 \tLoss KL: 0.027848 \tTime Interv: 19.184565\n",
      "Train Epoch: 1 [60800/162078 (38%)]\tLoss MSE: 0.071683 \tLoss KL: 0.027037 \tTime Interv: 19.161402\n",
      "Train Epoch: 1 [64000/162078 (39%)]\tLoss MSE: 0.082977 \tLoss KL: 0.026653 \tTime Interv: 19.163841\n",
      "Train Epoch: 1 [67200/162078 (41%)]\tLoss MSE: 0.078136 \tLoss KL: 0.026227 \tTime Interv: 19.176104\n",
      "Train Epoch: 1 [70400/162078 (43%)]\tLoss MSE: 0.074794 \tLoss KL: 0.026069 \tTime Interv: 19.175137\n",
      "Train Epoch: 1 [73600/162078 (45%)]\tLoss MSE: 0.074931 \tLoss KL: 0.025914 \tTime Interv: 19.173489\n",
      "Train Epoch: 1 [76800/162078 (47%)]\tLoss MSE: 0.076625 \tLoss KL: 0.025983 \tTime Interv: 19.156647\n",
      "Train Epoch: 1 [80000/162078 (49%)]\tLoss MSE: 0.072128 \tLoss KL: 0.025838 \tTime Interv: 19.165784\n",
      "Train Epoch: 1 [83200/162078 (51%)]\tLoss MSE: 0.072217 \tLoss KL: 0.025814 \tTime Interv: 19.174231\n",
      "Train Epoch: 1 [86400/162078 (53%)]\tLoss MSE: 0.079050 \tLoss KL: 0.025786 \tTime Interv: 19.175505\n",
      "Train Epoch: 1 [89600/162078 (55%)]\tLoss MSE: 0.076998 \tLoss KL: 0.025733 \tTime Interv: 19.161138\n",
      "Train Epoch: 1 [92800/162078 (57%)]\tLoss MSE: 0.083337 \tLoss KL: 0.025516 \tTime Interv: 19.149429\n",
      "Train Epoch: 1 [96000/162078 (59%)]\tLoss MSE: 0.081822 \tLoss KL: 0.025698 \tTime Interv: 19.186805\n",
      "Train Epoch: 1 [99200/162078 (61%)]\tLoss MSE: 0.074179 \tLoss KL: 0.025787 \tTime Interv: 19.176919\n",
      "Train Epoch: 1 [102400/162078 (63%)]\tLoss MSE: 0.077341 \tLoss KL: 0.025792 \tTime Interv: 19.163459\n",
      "Train Epoch: 1 [105600/162078 (65%)]\tLoss MSE: 0.077781 \tLoss KL: 0.025664 \tTime Interv: 19.163512\n",
      "Train Epoch: 1 [108800/162078 (67%)]\tLoss MSE: 0.075669 \tLoss KL: 0.025832 \tTime Interv: 19.137516\n",
      "Train Epoch: 1 [112000/162078 (69%)]\tLoss MSE: 0.085021 \tLoss KL: 0.025936 \tTime Interv: 19.162429\n",
      "Train Epoch: 1 [115200/162078 (71%)]\tLoss MSE: 0.070397 \tLoss KL: 0.025700 \tTime Interv: 19.171054\n",
      "Train Epoch: 1 [118400/162078 (73%)]\tLoss MSE: 0.077074 \tLoss KL: 0.025991 \tTime Interv: 19.169611\n",
      "Train Epoch: 1 [121600/162078 (75%)]\tLoss MSE: 0.076836 \tLoss KL: 0.025787 \tTime Interv: 19.178369\n",
      "Train Epoch: 1 [124800/162078 (77%)]\tLoss MSE: 0.072081 \tLoss KL: 0.025846 \tTime Interv: 19.169989\n",
      "Train Epoch: 1 [128000/162078 (79%)]\tLoss MSE: 0.081268 \tLoss KL: 0.025768 \tTime Interv: 19.161113\n",
      "Train Epoch: 1 [131200/162078 (81%)]\tLoss MSE: 0.076773 \tLoss KL: 0.025710 \tTime Interv: 19.161880\n",
      "Train Epoch: 1 [134400/162078 (83%)]\tLoss MSE: 0.074330 \tLoss KL: 0.025800 \tTime Interv: 19.156510\n",
      "Train Epoch: 1 [137600/162078 (85%)]\tLoss MSE: 0.077544 \tLoss KL: 0.026049 \tTime Interv: 19.163675\n",
      "Train Epoch: 1 [140800/162078 (87%)]\tLoss MSE: 0.073533 \tLoss KL: 0.026100 \tTime Interv: 19.153551\n",
      "Train Epoch: 1 [144000/162078 (89%)]\tLoss MSE: 0.070533 \tLoss KL: 0.026078 \tTime Interv: 19.181967\n",
      "Train Epoch: 1 [147200/162078 (91%)]\tLoss MSE: 0.068872 \tLoss KL: 0.026011 \tTime Interv: 19.164736\n",
      "Train Epoch: 1 [150400/162078 (93%)]\tLoss MSE: 0.077069 \tLoss KL: 0.026062 \tTime Interv: 19.193392\n",
      "Train Epoch: 1 [153600/162078 (95%)]\tLoss MSE: 0.076392 \tLoss KL: 0.026000 \tTime Interv: 19.161851\n",
      "Train Epoch: 1 [156800/162078 (97%)]\tLoss MSE: 0.072693 \tLoss KL: 0.026125 \tTime Interv: 19.165307\n",
      "Train Epoch: 1 [160000/162078 (99%)]\tLoss MSE: 0.071075 \tLoss KL: 0.026138 \tTime Interv: 19.200809\n",
      "====> Epoch: 1 Average loss: 0.126012 Elapsed Time: 959.574267\n",
      "====> Test set loss-mse: 0.075084, loss-kl: 0.026208\n",
      "====> Test set loss-mse: 0.128408, loss-kl: 0.029993\n",
      "Train Epoch: 2 [0/162078 (0%)]\tLoss MSE: 0.075450 \tLoss KL: 0.026208 \tTime Interv: 0.518376\n",
      "Train Epoch: 2 [3200/162078 (2%)]\tLoss MSE: 0.071584 \tLoss KL: 0.026104 \tTime Interv: 19.148988\n",
      "Train Epoch: 2 [6400/162078 (4%)]\tLoss MSE: 0.079078 \tLoss KL: 0.026116 \tTime Interv: 19.154867\n",
      "Train Epoch: 2 [9600/162078 (6%)]\tLoss MSE: 0.067966 \tLoss KL: 0.026207 \tTime Interv: 19.153113\n",
      "Train Epoch: 2 [12800/162078 (8%)]\tLoss MSE: 0.080183 \tLoss KL: 0.026255 \tTime Interv: 19.149522\n",
      "Train Epoch: 2 [16000/162078 (10%)]\tLoss MSE: 0.071943 \tLoss KL: 0.026440 \tTime Interv: 19.152958\n",
      "Train Epoch: 2 [19200/162078 (12%)]\tLoss MSE: 0.065876 \tLoss KL: 0.026407 \tTime Interv: 19.147843\n",
      "Train Epoch: 2 [22400/162078 (14%)]\tLoss MSE: 0.070880 \tLoss KL: 0.026403 \tTime Interv: 19.161340\n",
      "Train Epoch: 2 [25600/162078 (16%)]\tLoss MSE: 0.074524 \tLoss KL: 0.026291 \tTime Interv: 19.178595\n",
      "Train Epoch: 2 [28800/162078 (18%)]\tLoss MSE: 0.074871 \tLoss KL: 0.026439 \tTime Interv: 19.160294\n",
      "Train Epoch: 2 [32000/162078 (20%)]\tLoss MSE: 0.084371 \tLoss KL: 0.026200 \tTime Interv: 19.172617\n",
      "Train Epoch: 2 [35200/162078 (22%)]\tLoss MSE: 0.069789 \tLoss KL: 0.026435 \tTime Interv: 19.162644\n",
      "Train Epoch: 2 [38400/162078 (24%)]\tLoss MSE: 0.069077 \tLoss KL: 0.026510 \tTime Interv: 19.158667\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train(epoch)\n",
    "    test(epoch, '_on', True)\n",
    "    test(epoch, '_off', False)\n",
    "    model.train(False)\n",
    "    with torch.no_grad():\n",
    "        sample = torch.randn(BATCH_SIZE, BOTTLENECK_SIZE).to(device)\n",
    "        sample = model.decode(sample).cpu()\n",
    "        save_image(sample.view(BATCH_SIZE, 3, 200, 200),\n",
    "                   SAVE_RESULTS + '/sample_off_' + str(epoch) + '.png', normalize=True)\n",
    "    model.train(True)\n",
    "    with torch.no_grad():\n",
    "        sample = torch.randn(BATCH_SIZE, BOTTLENECK_SIZE).to(device)\n",
    "        sample = model.decode(sample).cpu()\n",
    "        save_image(sample.view(BATCH_SIZE, 3, 200, 200),\n",
    "                   SAVE_RESULTS + '/sample_on' + str(epoch) + '.png', normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.randn(BATCH_SIZE, BOTTLENECK_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.Tensor([[1,2,2,4]])\n",
    "x.exp().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_v = Variable(x.data.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.new(x.size()).normal_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.normal_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [train_loader_celeba.dataset[i][0].view(1,3,200,200) for i in range(100, 132)]\n",
    "'''img = img.view(1,3,200,200)\n",
    "data = img\n",
    "data.shape'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 34\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.cat(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(True)\n",
    "train_loss = 0\n",
    "\n",
    "data = data.to(device)\n",
    "optimizer.zero_grad()\n",
    "recon_batch, mu, logvar = model(data)\n",
    "loss_mse, loss_kl = loss_custom(recon_batch, data, mu, logvar)\n",
    "loss = loss_mse + loss_kl\n",
    "loss.backward()\n",
    "train_loss += loss.item()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_mse/32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dif = (recon_batch - data)\n",
    "dif.pow(2).sum()/(200*200*3*32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_kl/32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            }, SAVE_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample = 4\n",
    "sample_out1 = 5\n",
    "sample_out2 = 6\n",
    "sample = torch.randn(4, BOTTLENECK_SIZE).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_out1 = model.decode(sample).cpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 200, 200])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_out1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VAE_CNN(\n",
       "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (mxp1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (mxp2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (mxp3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (mxp4): MaxPool2d(kernel_size=2, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=43264, out_features=512, bias=True)\n",
       "  (fc_bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc2): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (fc_bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc3): Linear(in_features=512, out_features=43264, bias=True)\n",
       "  (fc_bn3): BatchNorm1d(43264, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (ups5): Upsample(scale_factor=2.0, mode=nearest)\n",
       "  (conv5): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (ups6): Upsample(scale_factor=2.0, mode=nearest)\n",
       "  (conv6): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (ups7): Upsample(scale_factor=2.0, mode=nearest)\n",
       "  (conv7): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (ups8): Upsample(scale_factor=2.0, mode=nearest)\n",
       "  (conv8): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn8): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv9): ConvTranspose2d(32, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu): ReLU()\n",
       "  (tanh): Tanh()\n",
       ")"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_out2 = model.decode(sample).cpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sample_out1-sample_out2).detach().numpy().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.train(True)\n",
    "sample = model.decode(sample).cpu()\n",
    "save_image(sample.view(BATCH_SIZE, 3, 200, 200),\n",
    "                   SAVE_RESULTS + '/sample_on_semnograd_' + str(epoch) + '.png', normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([0.9292, 0.8448, 0.9831, 1.0190, 0.9913, 0.9115, 0.9428, 1.0651, 0.8819,\n",
      "        0.9167, 1.1364, 1.1123, 1.1135, 1.0974, 0.9329, 1.0686, 0.9492, 0.9299,\n",
      "        1.1258, 1.1505, 1.1051, 0.9718, 1.0167, 0.9452, 1.1193, 1.0964, 0.8607,\n",
      "        0.9682, 1.1332, 1.0189, 0.9768, 1.1475], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0426, -0.1471, -0.0447,  0.0336,  0.0034, -0.1570,  0.0412,  0.1586,\n",
      "        -0.0386, -0.1243,  0.0757,  0.0099,  0.0115,  0.2145, -0.0811,  0.0070,\n",
      "        -0.0220, -0.0144,  0.2599,  0.2122,  0.0909, -0.0056,  0.0440,  0.0563,\n",
      "         0.1553,  0.2559,  0.0633,  0.0504,  0.0123,  0.2103, -0.0083,  0.1816],\n",
      "       device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for i in model.bn1.parameters():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''from torchvision.utils import make_grid\n",
    "import matplotlib.pyplot as plt'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''%matplotlib inline\n",
    "def show(img):\n",
    "    npimg = img.detach().numpy()\n",
    "    plt.figure(figsize=(30, 10))\n",
    "    plt.imshow(np.transpose(npimg, (1,2,0)), interpolation='nearest')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''model.train(True)\n",
    "test_loss = 0\n",
    "for i, (data, _) in enumerate(val_loader_celeba):\n",
    "    data = data.to(device)\n",
    "    recon_batch, mu, logvar = model(data)\n",
    "    loss_mse, loss_kl = loss_custom(recon_batch, data, mu, logvar)\n",
    "    loss = loss_mse + loss_kl\n",
    "    test_loss += loss.item()\n",
    "    if i == 0:\n",
    "        n = min(data.size(0), 8)\n",
    "        comparison = torch.cat([data[:n],\n",
    "                                recon_batch.view(7, 3, 200, 200)[:n]])\n",
    "        show(make_grid(comparison.cpu(), nrow=n, normalize=True))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''checkpoint = torch.load('model_save')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''model.train(True)\n",
    "test_loss = 0\n",
    "for i, (data, _) in enumerate(val_loader_celeba):\n",
    "    data = data.to(device)\n",
    "    recon_batch, mu, logvar = model(data)\n",
    "    loss_mse, loss_kl = loss_custom(recon_batch, data, mu, logvar)\n",
    "    loss = loss_mse + loss_kl\n",
    "    test_loss += loss.item()\n",
    "    if i == 0:\n",
    "        n = min(data.size(0), 8)\n",
    "        comparison = torch.cat([data[:n],\n",
    "                                recon_batch.view(7, 3, 200, 200)[:n]])\n",
    "        show(make_grid(comparison.cpu(), nrow=n, normalize=True))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''import random\n",
    "x_test = []\n",
    "plt.figure(figsize=(30,10))\n",
    "num_figs = 1\n",
    "plt.figure(figsize=(15,100))\n",
    "plt.axis('off')\n",
    "plt.imshow(make_grid(comparison.cpu(), nrow=n, normalize=True).detach().numpy())\n",
    "\n",
    "for i in range(num_figs):\n",
    "    figure_Decoded = vae_2.predict(np.array([x_test[i].astype('float32')/127.5 -1]), batch_size = b_size)\n",
    "    plt.axis('off')\n",
    "    plt.subplot(num_figs,2,1+i*2)\n",
    "    plt.imshow(x_test[i])\n",
    "    plt.axis('off')\n",
    "    plt.subplot(num_figs,2,2 + i*2)\n",
    "    plt.imshow((figure_Decoded[0]+1)/2)\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "usage: ipykernel_launcher.py [-h] EMB_DIM ENC_HID_DIM DEC_HID_DIM  DROPOUT  LR\n",
      "ipykernel_launcher.py: error: argument EMB_DIM: invalid int value: '/home/danielprado/.local/share/jupyter/runtime/kernel-f85cc4eb-4dc2-4a30-bbdf-04d477db0c2b.json'\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danielprado/miniconda3/envs/portinari_pytorch/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3334: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "from skimage import io, transform\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import save_image\n",
    "from torchsummary import summary\n",
    "import pandas as pd\n",
    "import time\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "from emb_descricoes import preprocess\n",
    "\n",
    "import argparse\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Arguments for VAER')\n",
    "\n",
    "\n",
    "parser.add_argument('EMB_DIM', action=\"store\", type=int)\n",
    "parser.add_argument('DEC_HID_DIM', action=\"store\", type=int)\n",
    "parser.add_argument('ENC_HID_DIM', action=\"store\", type=int)\n",
    "parser.add_argument('ATTN_DIM', action=\"store\", type=int)\n",
    "\n",
    "parser.add_argument('DROPOUT', action=\"store\", type=float)\n",
    "parser.add_argument('LR', action=\"store\", type=float)\n",
    "\n",
    "print(parser.parse_args())\n",
    "read = parser.parse_args()\n",
    "\n",
    "ENC_HID_DIM = read.ENC_HID_DIM\n",
    "ENC_EMB_DIM = read.EMB_DIM\n",
    "DEC_EMB_DIM = read.EMB_DIM\n",
    "DEC_HID_DIM = read.DEC_HID_DIM\n",
    "\n",
    "\n",
    "\n",
    "ATTN_DIM = read.ATTN_DIM\n",
    "ENC_DROPOUT = read.DROPOUT\n",
    "DEC_DROPOUT = read.DROPOUT\n",
    "LR = read.LR\n",
    "\n",
    "EMBEDDING_DIM = 300\n",
    "LOG_INTERVAL = 40 \n",
    "MAX_LEN = 200\n",
    "BATCH_SIZE = 16\n",
    "N_EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Achou 526 retratos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danielprado/miniconda3/envs/portinari_pytorch/lib/python3.7/site-packages/keras_preprocessing/text.py:178: UserWarning: The `nb_words` argument in `Tokenizer` has been renamed `num_words`.\n",
      "  warnings.warn('The `nb_words` argument in `Tokenizer` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total words 571096\n",
      "null words 2376\n",
      "0.42 % de palavras nÃ£o encontradas no emb\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix, portinari_idx, retratos_idx, resto_idx, word_index, index_word = preprocess(True)\n",
    "no_cuda = False\n",
    "seed = 1\n",
    "cuda = not no_cuda and torch.cuda.is_available()\n",
    "torch.manual_seed(seed)\n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if cuda else {}\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "class PortinariDesc(Dataset):\n",
    "    def __init__(self, data) -> None:\n",
    "        super().__init__()\n",
    "        self.data = data\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "#cria o dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "train_retratos, val_retratos = model_selection.train_test_split(retratos_idx, test_size = 0.2, shuffle = True)\n",
    "train_resto, val_resto = model_selection.train_test_split(resto_idx, test_size = 0.2, shuffle = True)\n",
    "\n",
    "\n",
    "train = train_retratos + train_resto\n",
    "val = val_retratos + val_resto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train = [sent[:MAX_LEN] for sent in train]\n",
    "val = [sent[:MAX_LEN] for sent in val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_tensor = list(map(lambda x: torch.tensor(x), train))\n",
    "val_tensor = list(map(lambda x: torch.tensor(x), val))\n",
    "\n",
    "train_dataset = PortinariDesc(train_tensor)\n",
    "val_dataset = PortinariDesc(val_tensor)\n",
    "\n",
    "def pad_collate(batch):\n",
    "    xx = batch\n",
    "    x_lens = list(map(len, xx))\n",
    "\n",
    "    xx_pad = pad_sequence(xx, batch_first=True, padding_value=0, )\n",
    "\n",
    "    return xx_pad, x_lens\n",
    "\n",
    "#embedding_torch = nn.Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"unknown_tokens = [i for i in range(len(embedding_matrix)) if np.sum(embedding_matrix[i]-embedding_matrix[-1]) == 0]\\nfor tk in unknown_tokens:\\n    index_word[tk] = '<unk>'\\nfor w, idx in word_index.items():\\n    if np.sum(embedding_matrix[idx])==0:\\n        word_index[w] = len(embedding_matrix)-1\\npalavras_desconhecidas = [w for w, idx in word_index.items()  if np.sum(embedding_matrix[idx]-embedding_matrix[-1]) == 0]\\nlen(palavras_desconhecidas)\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''unknown_tokens = [i for i in range(len(embedding_matrix)) if np.sum(embedding_matrix[i]-embedding_matrix[-1]) == 0]\n",
    "for tk in unknown_tokens:\n",
    "    index_word[tk] = '<unk>'\n",
    "for w, idx in word_index.items():\n",
    "    if np.sum(embedding_matrix[idx])==0:\n",
    "        word_index[w] = len(embedding_matrix)-1\n",
    "palavras_desconhecidas = [w for w, idx in word_index.items()  if np.sum(embedding_matrix[idx]-embedding_matrix[-1]) == 0]\n",
    "len(palavras_desconhecidas)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_tensor = torch.Tensor(embedding_matrix).to(device)\n",
    "\n",
    "\n",
    "train_data_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, drop_last=True,\n",
    "    batch_size = BATCH_SIZE, shuffle=True, collate_fn=pad_collate)\n",
    "\n",
    "val_data_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset, drop_last=True,\n",
    "    batch_size = BATCH_SIZE, shuffle=True, collate_fn=pad_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from typing import Tuple\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "\n",
    "from text_models import Encoder, Decoder, Attention, Seq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''ENC_EMB_DIM = 256\n",
    "DEC_EMB_DIM = 256\n",
    "ENC_HID_DIM = 512\n",
    "DEC_HID_DIM = 512\n",
    "ATTN_DIM = 64\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5'''\n",
    "\n",
    "\n",
    "\n",
    "enc = Encoder(embedding_tensor, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT).to(device)\n",
    "attn = Attention(ENC_HID_DIM, DEC_HID_DIM, ATTN_DIM).to(device)\n",
    "dec = Decoder(embedding_tensor, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, attn).to(device)\n",
    "model = Seq2Seq(enc, dec, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def init_weights(m: nn.Module):\n",
    "    for name, param in m.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            nn.init.normal_(param.data, mean=0, std=0.01)\n",
    "        else:\n",
    "            nn.init.constant_(param.data, 0)\n",
    "\n",
    "model.apply(init_weights)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 4,429,283 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def count_parameters(model: nn.Module):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import math\\nimport time\\n\\n(x,x_l) = next(iter(data_loader))\\nx = x.to(device)\\nx_l = torch.Tensor(x_l).to(device)\\noutput = model(x.permute(1,0),x_l)'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import math\n",
    "import time\n",
    "\n",
    "(x,x_l) = next(iter(data_loader))\n",
    "x = x.to(device)\n",
    "x_l = torch.Tensor(x_l).to(device)\n",
    "output = model(x.permute(1,0),x_l)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "226"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "\n",
    "def train(model: nn.Module,\n",
    "          iterator: DataLoader,\n",
    "          optimizer: optim.Optimizer,\n",
    "          criterion: nn.Module,\n",
    "          clip: float,\n",
    "          epoch):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_start = 0\n",
    "    train_loss = 0\n",
    "    start = time.time()\n",
    "    \n",
    "    model.train(True)\n",
    "    \n",
    "    for batch_idx, (x,x_l) in enumerate(iterator):\n",
    "        \n",
    "        x = x.to(device)\n",
    "       \n",
    "        x_l = torch.Tensor(x_l).to(device)\n",
    "        \n",
    "        #print(f\"x = {x.shape}, x_l = {x_l.shape}\")\n",
    "        \n",
    "        output = model(x.permute(1,0),x_l)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        flat_output = output.view(-1, output.shape[-1])\n",
    "        target = x.permute(1,0).contiguous().view(-1)\n",
    "        \n",
    "        loss = criterion(flat_output, target)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        \n",
    "        if batch_idx % LOG_INTERVAL == 0:\n",
    "                interval = time.time() - start\n",
    "                start = time.time()\n",
    "                epoch_start = epoch_start + interval\n",
    "\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss : {:.6f} \\tTime Interv: {:.6f}'.format(\n",
    "                    epoch, batch_idx * len(x), len(iterator.dataset),\n",
    "                           100. * batch_idx / len(iterator),\n",
    "                           loss.item(), interval))\n",
    "        #del(x)\n",
    "        #del(x_l)\n",
    "        #torch.cuda.empty_cache()\n",
    "            \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model: nn.Module,\n",
    "             iterator: DataLoader,\n",
    "             criterion: nn.Module):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    epoch_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for batch_idx, (x,x_l) in enumerate(iterator):\n",
    "\n",
    "            x = x.to(device)\n",
    "\n",
    "            x_l = torch.Tensor(x_l).to(device)\n",
    "            \n",
    "            output = model(x.permute(1,0),x_l, 0)\n",
    "\n",
    "            flat_output = output.view(-1, output.shape[-1])\n",
    "            target = x.permute(1,0).contiguous().view(-1)\n",
    "\n",
    "            loss = criterion(flat_output, target)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            del(x)\n",
    "            del(x_l)\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/3630 (0%)]\tLoss : 9.046326 \tTime Interv: 0.980478\n",
      "Train Epoch: 0 [640/3630 (18%)]\tLoss : 5.897495 \tTime Interv: 31.417345\n",
      "Train Epoch: 0 [1280/3630 (35%)]\tLoss : 5.913294 \tTime Interv: 31.709690\n",
      "Train Epoch: 0 [1920/3630 (53%)]\tLoss : 5.704523 \tTime Interv: 31.503156\n",
      "Train Epoch: 0 [2560/3630 (71%)]\tLoss : 5.871801 \tTime Interv: 32.381515\n",
      "Train Epoch: 0 [3200/3630 (88%)]\tLoss : 5.647846 \tTime Interv: 31.979170\n",
      "Epoch: 01 | Time: 3m 5s\n",
      "\tTrain Loss: 5.958 | Train PPL: 386.956\n",
      "\t Val. Loss: 5.780 |  Val. PPL: 323.726\n",
      "Train Epoch: 1 [0/3630 (0%)]\tLoss : 5.581927 \tTime Interv: 0.690814\n",
      "Train Epoch: 1 [640/3630 (18%)]\tLoss : 5.535550 \tTime Interv: 32.007462\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-e0cfdd062daf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mlast_valid_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCLIP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mvalid_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalid_loss\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mlast_valid_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-1e6dedd189cb>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion, clip, epoch)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/portinari_pytorch/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \"\"\"\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/portinari_pytorch/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def epoch_time(start_time: int,\n",
    "               end_time: int):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n",
    "\n",
    "\n",
    "CLIP = 1\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "last_valid_loss = 100\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss = train(model, train_data_loader, optimizer, criterion, CLIP, epoch)\n",
    "    valid_loss = evaluate(model, val_data_loader, criterion)\n",
    "    if valid_loss > last_valid_loss:\n",
    "        print('\\nshould break!!!')\n",
    "        epoch = N_EPOCHS;\n",
    "    last_valid_loss = valid_loss\n",
    "    \n",
    "    end_time = time.time()\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "(x,x_l) = next(iter(train_data_loader))\n",
    "x = x.to(device)\n",
    "x_l_tens = torch.Tensor(x_l).to(device)\n",
    "output = model(x.permute(1,0),x_l_tens, 0)\n",
    "out = output.argmax(-1).transpose(1,0).cpu().numpy().tolist()\n",
    "inp = x.cpu().numpy().tolist()\n",
    "inp_text = [[index_word[token] if token != 0 else 'NUll' for token in sentence ] \n",
    "          for sentence in inp]\n",
    "out_text = [[index_word[token] if token != 0 else 'NUll' for token in sentence ] \n",
    "              for sentence in out]\n",
    "\n",
    "print('\\nTrain = True')\n",
    "print('\\nfrase inp:', inp_text[0][0:x_l[0]+1])\n",
    "print('\\nfrase out:',  out_text[0][0:x_l[0]+1])\n",
    "\n",
    "print('\\nTrain = False')\n",
    "\n",
    "model.eval()\n",
    "output = model(x.permute(1,0),x_l_tens, 0)\n",
    "out = output.argmax(-1).transpose(1,0).cpu().numpy().tolist()\n",
    "inp = x.cpu().numpy().tolist()\n",
    "inp_text = [[index_word[token] if token != 0 else 'NUll' for token in sentence ] \n",
    "          for sentence in inp]\n",
    "out_text = [[index_word[token] if token != 0 else 'NUll' for token in sentence ] \n",
    "              for sentence in out]\n",
    "print('\\nfrase inp:', inp_text[0][0:x_l[0]+1])\n",
    "print('\\nfrase out:',  out_text[0][0:x_l[0]+1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

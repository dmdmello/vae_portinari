{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "from skimage import io, transform\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import save_image\n",
    "from torchsummary import summary\n",
    "import pandas as pd\n",
    "import time\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "from emb_descricoes import preprocess\n",
    "\n",
    "EMBEDDING_DIM = 300\n",
    "LOG_INTERVAL = 40 \n",
    "MAX_LEN = 200\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "K = 1\n",
    "ENC_EMB_DIM = K*32\n",
    "DEC_EMB_DIM = K*32\n",
    "ENC_HID_DIM = K*64\n",
    "DEC_HID_DIM = K*64\n",
    "ATTN_DIM = K*8\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Achou 526 retratos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danielprado/miniconda3/envs/portinari_pytorch_1.3/lib/python3.7/site-packages/keras_preprocessing/text.py:178: UserWarning: The `nb_words` argument in `Tokenizer` has been renamed `num_words`.\n",
      "  warnings.warn('The `nb_words` argument in `Tokenizer` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total words 571096\n",
      "null words 2376\n",
      "0.42 % de palavras não encontradas no emb\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix, portinari_idx, retratos_idx, resto_idx, word_index, index_word = preprocess(True)\n",
    "no_cuda = False\n",
    "seed = 1\n",
    "cuda = not no_cuda and torch.cuda.is_available()\n",
    "torch.manual_seed(seed)\n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if cuda else {}\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "class PortinariDesc(Dataset):\n",
    "    def __init__(self, data) -> None:\n",
    "        super().__init__()\n",
    "        self.data = data\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "#cria o dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "train_retratos, val_retratos = model_selection.train_test_split(retratos_idx, test_size = 0.2, shuffle = True)\n",
    "train_resto, val_resto = model_selection.train_test_split(resto_idx, test_size = 0.2, shuffle = True)\n",
    "\n",
    "\n",
    "train = train_retratos + train_resto\n",
    "val = val_retratos + val_resto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train = [sent[:MAX_LEN] for sent in train]\n",
    "val = [sent[:MAX_LEN] for sent in val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_tensor = list(map(lambda x: torch.tensor(x), train))\n",
    "val_tensor = list(map(lambda x: torch.tensor(x), val))\n",
    "\n",
    "train_dataset = PortinariDesc(train_tensor)\n",
    "val_dataset = PortinariDesc(val_tensor)\n",
    "\n",
    "def pad_collate(batch):\n",
    "    xx = batch\n",
    "    x_lens = list(map(len, xx))\n",
    "\n",
    "    xx_pad = pad_sequence(xx, batch_first=True, padding_value=0, )\n",
    "\n",
    "    return xx_pad, x_lens\n",
    "\n",
    "#embedding_torch = nn.Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"unknown_tokens = [i for i in range(len(embedding_matrix)) if np.sum(embedding_matrix[i]-embedding_matrix[-1]) == 0]\\nfor tk in unknown_tokens:\\n    index_word[tk] = '<unk>'\\nfor w, idx in word_index.items():\\n    if np.sum(embedding_matrix[idx])==0:\\n        word_index[w] = len(embedding_matrix)-1\\npalavras_desconhecidas = [w for w, idx in word_index.items()  if np.sum(embedding_matrix[idx]-embedding_matrix[-1]) == 0]\\nlen(palavras_desconhecidas)\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''unknown_tokens = [i for i in range(len(embedding_matrix)) if np.sum(embedding_matrix[i]-embedding_matrix[-1]) == 0]\n",
    "for tk in unknown_tokens:\n",
    "    index_word[tk] = '<unk>'\n",
    "for w, idx in word_index.items():\n",
    "    if np.sum(embedding_matrix[idx])==0:\n",
    "        word_index[w] = len(embedding_matrix)-1\n",
    "palavras_desconhecidas = [w for w, idx in word_index.items()  if np.sum(embedding_matrix[idx]-embedding_matrix[-1]) == 0]\n",
    "len(palavras_desconhecidas)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_tensor = torch.Tensor(embedding_matrix).to(device)\n",
    "\n",
    "\n",
    "train_data_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, drop_last=True,\n",
    "    batch_size = BATCH_SIZE, shuffle=True, collate_fn=pad_collate)\n",
    "\n",
    "val_data_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset, drop_last=True,\n",
    "    batch_size = BATCH_SIZE, shuffle=True, collate_fn=pad_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from typing import Tuple\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "\n",
    "from text_models import Encoder, Decoder, Attention, Seq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''ENC_EMB_DIM = 256\n",
    "DEC_EMB_DIM = 256\n",
    "ENC_HID_DIM = 512\n",
    "DEC_HID_DIM = 512\n",
    "ATTN_DIM = 64\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5'''\n",
    "\n",
    "\n",
    "\n",
    "enc = Encoder(embedding_tensor, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT).to(device)\n",
    "attn = Attention(ENC_HID_DIM, DEC_HID_DIM, ATTN_DIM).to(device)\n",
    "dec = Decoder(embedding_tensor, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, attn).to(device)\n",
    "model = Seq2Seq(enc, dec, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def init_weights(m: nn.Module):\n",
    "    for name, param in m.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            nn.init.normal_(param.data, mean=0, std=0.01)\n",
    "        else:\n",
    "            nn.init.constant_(param.data, 0)\n",
    "\n",
    "model.apply(init_weights)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 4,429,283 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def count_parameters(model: nn.Module):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import math\\nimport time\\n\\n(x,x_l) = next(iter(data_loader))\\nx = x.to(device)\\nx_l = torch.Tensor(x_l).to(device)\\noutput = model(x.permute(1,0),x_l)'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import math\n",
    "import time\n",
    "\n",
    "(x,x_l) = next(iter(data_loader))\n",
    "x = x.to(device)\n",
    "x_l = torch.Tensor(x_l).to(device)\n",
    "output = model(x.permute(1,0),x_l)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "226"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "\n",
    "def train(model: nn.Module,\n",
    "          iterator: DataLoader,\n",
    "          optimizer: optim.Optimizer,\n",
    "          criterion: nn.Module,\n",
    "          clip: float,\n",
    "          epoch):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_start = 0\n",
    "    train_loss = 0\n",
    "    start = time.time()\n",
    "    \n",
    "    model.train(True)\n",
    "    \n",
    "    for batch_idx, (x,x_l) in enumerate(iterator):\n",
    "        \n",
    "        x = x.to(device)\n",
    "       \n",
    "        x_l = torch.Tensor(x_l).to(device)\n",
    "        \n",
    "        #print(f\"x = {x.shape}, x_l = {x_l.shape}\")\n",
    "        \n",
    "        output = model(x.permute(1,0),x_l)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        flat_output = output.view(-1, output.shape[-1])\n",
    "        target = x.permute(1,0).contiguous().view(-1)\n",
    "        \n",
    "        loss = criterion(flat_output, target)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        \n",
    "        if batch_idx % LOG_INTERVAL == 0:\n",
    "                interval = time.time() - start\n",
    "                start = time.time()\n",
    "                epoch_start = epoch_start + interval\n",
    "\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss : {:.6f} \\tTime Interv: {:.6f}'.format(\n",
    "                    epoch, batch_idx * len(x), len(iterator.dataset),\n",
    "                           100. * batch_idx / len(iterator),\n",
    "                           loss.item(), interval))\n",
    "        #del(x)\n",
    "        #del(x_l)\n",
    "        #torch.cuda.empty_cache()\n",
    "            \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model: nn.Module,\n",
    "             iterator: DataLoader,\n",
    "             criterion: nn.Module):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    epoch_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for batch_idx, (x,x_l) in enumerate(iterator):\n",
    "\n",
    "            x = x.to(device)\n",
    "\n",
    "            x_l = torch.Tensor(x_l).to(device)\n",
    "            \n",
    "            output = model(x.permute(1,0),x_l, 0)\n",
    "\n",
    "            flat_output = output.view(-1, output.shape[-1])\n",
    "            target = x.permute(1,0).contiguous().view(-1)\n",
    "\n",
    "            loss = criterion(flat_output, target)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            del(x)\n",
    "            del(x_l)\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/3630 (0%)]\tLoss : 9.046380 \tTime Interv: 0.971700\n",
      "Train Epoch: 0 [640/3630 (18%)]\tLoss : 6.216505 \tTime Interv: 32.039174\n",
      "Train Epoch: 0 [1280/3630 (35%)]\tLoss : 5.809929 \tTime Interv: 31.944799\n",
      "Train Epoch: 0 [1920/3630 (53%)]\tLoss : 6.066749 \tTime Interv: 32.027677\n",
      "Train Epoch: 0 [2560/3630 (71%)]\tLoss : 5.534132 \tTime Interv: 32.204547\n",
      "Train Epoch: 0 [3200/3630 (88%)]\tLoss : 5.413165 \tTime Interv: 31.165215\n",
      "Epoch: 01 | Time: 3m 6s\n",
      "\tTrain Loss: 5.855 | Train PPL: 348.991\n",
      "\t Val. Loss: 5.931 |  Val. PPL: 376.386\n",
      "Train Epoch: 1 [0/3630 (0%)]\tLoss : 5.144667 \tTime Interv: 0.816949\n",
      "Train Epoch: 1 [640/3630 (18%)]\tLoss : 5.226858 \tTime Interv: 31.810459\n",
      "Train Epoch: 1 [1280/3630 (35%)]\tLoss : 5.257027 \tTime Interv: 32.399898\n",
      "Train Epoch: 1 [1920/3630 (53%)]\tLoss : 4.860270 \tTime Interv: 31.035315\n",
      "Train Epoch: 1 [2560/3630 (71%)]\tLoss : 4.985868 \tTime Interv: 31.602117\n",
      "Train Epoch: 1 [3200/3630 (88%)]\tLoss : 5.096562 \tTime Interv: 31.802542\n",
      "Epoch: 02 | Time: 3m 4s\n",
      "\tTrain Loss: 5.103 | Train PPL: 164.575\n",
      "\t Val. Loss: 6.066 |  Val. PPL: 430.898\n",
      "Train Epoch: 2 [0/3630 (0%)]\tLoss : 4.921801 \tTime Interv: 0.817986\n",
      "Train Epoch: 2 [640/3630 (18%)]\tLoss : 4.854976 \tTime Interv: 32.171583\n",
      "Train Epoch: 2 [1280/3630 (35%)]\tLoss : 4.807927 \tTime Interv: 32.148300\n",
      "Train Epoch: 2 [1920/3630 (53%)]\tLoss : 4.673577 \tTime Interv: 31.732491\n",
      "Train Epoch: 2 [2560/3630 (71%)]\tLoss : 4.958985 \tTime Interv: 32.067739\n",
      "Train Epoch: 2 [3200/3630 (88%)]\tLoss : 4.972431 \tTime Interv: 32.166539\n",
      "Epoch: 03 | Time: 3m 7s\n",
      "\tTrain Loss: 4.913 | Train PPL: 135.999\n",
      "\t Val. Loss: 5.846 |  Val. PPL: 345.893\n",
      "Train Epoch: 3 [0/3630 (0%)]\tLoss : 4.607247 \tTime Interv: 0.817223\n"
     ]
    }
   ],
   "source": [
    "def epoch_time(start_time: int,\n",
    "               end_time: int):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n",
    "\n",
    "\n",
    "N_EPOCHS = 20\n",
    "CLIP = 1\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss = train(model, train_data_loader, optimizer, criterion, CLIP, epoch)\n",
    "    valid_loss = evaluate(model, val_data_loader, criterion)\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "(x,x_l) = next(iter(train_data_loader))\n",
    "x = x.to(device)\n",
    "x_l_tens = torch.Tensor(x_l).to(device)\n",
    "output = model(x.permute(1,0),x_l_tens, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = output.argmax(-1).transpose(1,0).cpu().numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = x.cpu().numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_text = [[index_word[token] if token != 0 else 'NUll' for token in sentence ] \n",
    "          for sentence in inp]\n",
    "out_text = [[index_word[token] if token != 0 else 'NUll' for token in sentence ] \n",
    "              for sentence in out]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['composição',\n",
       " 'em',\n",
       " 'tons',\n",
       " 'escuros',\n",
       " 'de',\n",
       " 'preto',\n",
       " 'cinzas',\n",
       " 'e',\n",
       " 'terras',\n",
       " 'e',\n",
       " 'nos',\n",
       " 'tons',\n",
       " 'branco',\n",
       " 'ocre',\n",
       " 'rosa',\n",
       " 'vermelho',\n",
       " 'azul',\n",
       " 'claro',\n",
       " 'textura',\n",
       " 'lisa',\n",
       " 'retrato',\n",
       " 'de',\n",
       " 'mulher',\n",
       " 'contra',\n",
       " 'fundo',\n",
       " 'cinza',\n",
       " 'dégradé',\n",
       " 'retratada',\n",
       " 'está',\n",
       " 'de',\n",
       " 'frente',\n",
       " 'meio',\n",
       " 'corpo',\n",
       " 'com',\n",
       " 'rosto',\n",
       " 'quase',\n",
       " '<unk>',\n",
       " '<unk>',\n",
       " 'a',\n",
       " 'esquerda',\n",
       " 'tem',\n",
       " 'cabelos',\n",
       " 'curtos',\n",
       " 'e',\n",
       " 'escuros',\n",
       " 'repartidos',\n",
       " 'a',\n",
       " 'direita',\n",
       " 'e',\n",
       " 'enrolados',\n",
       " 'em',\n",
       " 'pequenos',\n",
       " 'cachos',\n",
       " 'de',\n",
       " 'onde',\n",
       " 'saem',\n",
       " 'as',\n",
       " 'pontas',\n",
       " 'dos',\n",
       " 'papelotes',\n",
       " 'sobrancelhas',\n",
       " 'são',\n",
       " 'finas',\n",
       " 'pretas',\n",
       " 'e',\n",
       " 'retas',\n",
       " 'olhos',\n",
       " 'escuros',\n",
       " 'pequenos',\n",
       " 'e',\n",
       " 'amendoados',\n",
       " 'nariz',\n",
       " 'fino',\n",
       " 'e',\n",
       " 'longo',\n",
       " 'lábios',\n",
       " 'fechados',\n",
       " 'pintados',\n",
       " 'de',\n",
       " 'vermelho',\n",
       " 'queixo',\n",
       " 'fino',\n",
       " 'rosto',\n",
       " 'magro',\n",
       " 'e',\n",
       " 'comprido',\n",
       " 'com',\n",
       " 'toques',\n",
       " 'de',\n",
       " 'rosa',\n",
       " 'nas',\n",
       " 'faces',\n",
       " 'luz',\n",
       " 'incidindo',\n",
       " 'a',\n",
       " 'direita',\n",
       " 'e',\n",
       " 'iluminando',\n",
       " 'sua',\n",
       " 'face',\n",
       " 'esquerda',\n",
       " 'enquanto',\n",
       " 'a',\n",
       " 'face',\n",
       " 'direita',\n",
       " 'está',\n",
       " 'parcialmente',\n",
       " 'sombria',\n",
       " 'sombra',\n",
       " 'se',\n",
       " 'estende',\n",
       " 'a',\n",
       " 'esquerda',\n",
       " 'sobre',\n",
       " 'o',\n",
       " 'pescoço',\n",
       " 'fino',\n",
       " 'usa',\n",
       " 'vestido',\n",
       " 'preto',\n",
       " 'com',\n",
       " 'gola',\n",
       " 'subindo',\n",
       " 'um',\n",
       " 'pouco',\n",
       " 'pelo',\n",
       " 'pescoço',\n",
       " 'e',\n",
       " 'mangas',\n",
       " 'compridas',\n",
       " 'fundo',\n",
       " 'cinza',\n",
       " 'dégradé',\n",
       " 'com',\n",
       " 'base',\n",
       " 'e',\n",
       " 'topo',\n",
       " 'em',\n",
       " 'tons',\n",
       " 'escuros',\n",
       " 'que',\n",
       " 'vão',\n",
       " 'clareando',\n",
       " 'em',\n",
       " 'direção',\n",
       " 'ao',\n",
       " 'centro',\n",
       " 'retrato',\n",
       " 'da',\n",
       " 'baronesa',\n",
       " 'carmem',\n",
       " 'saavedra',\n",
       " 'NUll']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_text[0][0:x_l[0]+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['composição',\n",
       " 'nos',\n",
       " 'preto',\n",
       " 'preto',\n",
       " 'e',\n",
       " 'branco',\n",
       " 'e',\n",
       " 'branco',\n",
       " 'linhas',\n",
       " 'de',\n",
       " 'e',\n",
       " 'e',\n",
       " 'de',\n",
       " 'de',\n",
       " 'de',\n",
       " 'de',\n",
       " 'de',\n",
       " 'de',\n",
       " 'de',\n",
       " 'de',\n",
       " 'de',\n",
       " 'de',\n",
       " 'de',\n",
       " 'a',\n",
       " 'fundo',\n",
       " 'de',\n",
       " 'de',\n",
       " 'de',\n",
       " 'a',\n",
       " 'de',\n",
       " 'a',\n",
       " 'de',\n",
       " 'de',\n",
       " 'e',\n",
       " 'a',\n",
       " 'de',\n",
       " 'a',\n",
       " 'de',\n",
       " 'de',\n",
       " 'a',\n",
       " 'e',\n",
       " 'de',\n",
       " 'e',\n",
       " 'e',\n",
       " 'e',\n",
       " 'e',\n",
       " 'e',\n",
       " 'e',\n",
       " 'e',\n",
       " 'e',\n",
       " 'e',\n",
       " 'e',\n",
       " 'e',\n",
       " 'e',\n",
       " 'de',\n",
       " 'e',\n",
       " 'e',\n",
       " 'e',\n",
       " 'e',\n",
       " 'e',\n",
       " 'de',\n",
       " 'a',\n",
       " 'e',\n",
       " 'e',\n",
       " 'e',\n",
       " 'e',\n",
       " 'e',\n",
       " 'e',\n",
       " 'e',\n",
       " 'e',\n",
       " 'e',\n",
       " 'e',\n",
       " 'a',\n",
       " 'e',\n",
       " 'e',\n",
       " 'de',\n",
       " 'a',\n",
       " 'e',\n",
       " 'e',\n",
       " 'e',\n",
       " 'e',\n",
       " 'a',\n",
       " 'e',\n",
       " 'e',\n",
       " 'e',\n",
       " 'e',\n",
       " 'e',\n",
       " 'e',\n",
       " 'e',\n",
       " 'e',\n",
       " 'e',\n",
       " 'e',\n",
       " 'e',\n",
       " 'e',\n",
       " 'e',\n",
       " 'e',\n",
       " 'e',\n",
       " 'e',\n",
       " 'e',\n",
       " 'e',\n",
       " 'e',\n",
       " 'e',\n",
       " 'e',\n",
       " 'e',\n",
       " 'e',\n",
       " 'e',\n",
       " 'e',\n",
       " 'de',\n",
       " 'a',\n",
       " 'e',\n",
       " 'e',\n",
       " 'e',\n",
       " 'e',\n",
       " 'de',\n",
       " 'de',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'de',\n",
       " 'a',\n",
       " 'esquerda',\n",
       " 'e',\n",
       " 'de',\n",
       " 'e',\n",
       " 'e',\n",
       " 'e',\n",
       " 'e',\n",
       " 'e',\n",
       " 'e',\n",
       " 'e',\n",
       " 'e',\n",
       " 'e',\n",
       " 'de',\n",
       " 'a',\n",
       " 'a',\n",
       " 'esquerda',\n",
       " 'e',\n",
       " 'e',\n",
       " 'e',\n",
       " 'e',\n",
       " 'e',\n",
       " 'e',\n",
       " 'e',\n",
       " 'e',\n",
       " 'e',\n",
       " 'e',\n",
       " 'e',\n",
       " 'e',\n",
       " 'e',\n",
       " 'e',\n",
       " 'e',\n",
       " 'e',\n",
       " 'e']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_text[0][0:x_l[0]+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

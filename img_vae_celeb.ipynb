{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘../results/KL0005_64_model_novo’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "from skimage import io, transform\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import save_image\n",
    "from skimage.io import imread\n",
    "from torchsummary import summary\n",
    "import pandas as pd\n",
    "import time\n",
    "from image_models import *\n",
    "NAME = 'KL0005_64_model_novo'\n",
    "KL_PAR = 0.0005\n",
    "\n",
    "TRAIN_ROOT = '../data/data-celeba/Train'\n",
    "VAL_ROOT = '../data/data-celeba/Validation'\n",
    "VAL_ROOT_FIX = '../data/data-celeba/Fix_sample'\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 10\n",
    "LOG_INTERVAL = 50\n",
    "BOTTLENECK_SIZE = 512\n",
    "SAVE_MODEL = '../models/' + NAME\n",
    "SAVE_RESULTS = '../results/' + NAME\n",
    "%mkdir {SAVE_RESULTS}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_cuda = False\n",
    "seed = 1\n",
    "cuda = not no_cuda and torch.cuda.is_available()\n",
    "torch.manual_seed(seed)\n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if cuda else {}\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "\n",
    "transform_seq = [ transforms.Resize((200,163)), transforms.Pad(( 19, 0, 18, 0)),\n",
    "                  transforms.ToTensor(), transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))]\n",
    "\n",
    "train_loader_celeba = torch.utils.data.DataLoader(\n",
    "    datasets.ImageFolder(TRAIN_ROOT, transform=transforms.Compose(transform_seq)),\n",
    "    batch_size = BATCH_SIZE, shuffle=True, **kwargs)\n",
    "\n",
    "val_loader_celeba = torch.utils.data.DataLoader(\n",
    "    datasets.ImageFolder(VAL_ROOT, transform=transforms.Compose(transform_seq)),\n",
    "    batch_size = BATCH_SIZE, shuffle=True, **kwargs)\n",
    "\n",
    "val_loader_celeba_fix = torch.utils.data.DataLoader(\n",
    "    datasets.ImageFolder(VAL_ROOT_FIX, transform=transforms.Compose(transform_seq)),\n",
    "    batch_size = BATCH_SIZE, shuffle=False, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class customLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(customLoss, self).__init__()\n",
    "        self.mse_loss = nn.MSELoss(reduction=\"mean\")\n",
    "\n",
    "    def forward(self, x_recon, x, mu, logvar):\n",
    "        loss_MSE = self.mse_loss(x_recon, x)\n",
    "        loss_KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp(), dim = -1)\n",
    "        loss_KLD = torch.sum(loss_KLD*KL_PAR)/BATCH_SIZE\n",
    "        return loss_MSE, loss_KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE_CNN(BOTTLENECK_SIZE).to(device)\n",
    "optimizer = optim.RMSprop(model.parameters(), lr=0.001, alpha= 0.9)\n",
    "loss_custom = customLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VAE_CNN(\n",
       "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn1): BatchNorm2d(32, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "  (mxp1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn2): BatchNorm2d(64, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "  (mxp2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn3): BatchNorm2d(128, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "  (mxp3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn4): BatchNorm2d(256, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "  (mxp4): MaxPool2d(kernel_size=2, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=43264, out_features=512, bias=True)\n",
       "  (fc_bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc2): Linear(in_features=43264, out_features=512, bias=True)\n",
       "  (fc_bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc3): Linear(in_features=512, out_features=43264, bias=True)\n",
       "  (ups5): Upsample(scale_factor=2.0, mode=nearest)\n",
       "  (conv5): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn5): BatchNorm2d(256, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "  (ups6): Upsample(scale_factor=2.0, mode=nearest)\n",
       "  (conv6): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn6): BatchNorm2d(128, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "  (ups7): Upsample(scale_factor=2.0, mode=nearest)\n",
       "  (conv7): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn7): BatchNorm2d(64, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "  (ups8): Upsample(scale_factor=2.0, mode=nearest)\n",
       "  (conv8): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn8): BatchNorm2d(32, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "  (conv9): ConvTranspose2d(32, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu): ReLU()\n",
       "  (tanh): Tanh()\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#summary(model, (3,200,200))\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_losses = []\n",
    "train_losses = []\n",
    "\n",
    "def train(epoch):\n",
    "    epoch_start = 0\n",
    "    model.train(True)\n",
    "    train_loss = 0\n",
    "    start = time.time()\n",
    "    for batch_idx, (data, _) in enumerate(train_loader_celeba): \n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = model(data)\n",
    "        loss_mse, loss_kl = loss_custom(recon_batch, data, mu, logvar)\n",
    "        loss = loss_mse + loss_kl\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        if batch_idx % LOG_INTERVAL == 0:\n",
    "            interval = time.time() - start\n",
    "            start = time.time()\n",
    "            epoch_start = epoch_start + interval\n",
    "            \n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss MSE: {:.6f} \\tLoss KL: {:.6f} \\tTime Interv: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader_celeba.dataset),\n",
    "                       100. * batch_idx / len(train_loader_celeba),\n",
    "                       loss_mse.item(), loss_kl.item(), interval))\n",
    "\n",
    "    print('====> Epoch: {} Average loss: {:.6f} Elapsed Time: {:.6f}'.format(\n",
    "        epoch, train_loss * BATCH_SIZE / len(train_loader_celeba.dataset), epoch_start))\n",
    "    train_losses.append(train_loss*BATCH_SIZE/ len(train_loader_celeba.dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch, sufix, train):\n",
    "    model.train(train)\n",
    "    test_loss_mse = 0\n",
    "    test_loss_kl = 0\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for i, (data, _) in enumerate(val_loader_celeba):\n",
    "            data = data.to(device)\n",
    "            recon_batch, mu, logvar = model(data)\n",
    "            loss_mse, loss_kl = loss_custom(recon_batch, data, mu, logvar)\n",
    "            loss = loss_mse + loss_kl\n",
    "            test_loss_mse += loss_mse.item()\n",
    "            test_loss_kl += loss_kl.item()\n",
    "            \n",
    "        for i, (data, _) in enumerate(val_loader_celeba_fix):\n",
    "            data = data.to(device)\n",
    "            recon_batch, mu, logvar = model(data)\n",
    "            if i == 0:\n",
    "                n = min(data.size(0), 8)\n",
    "                comparison = torch.cat([data[:n],\n",
    "                                        recon_batch.view(7, 3, 200, 200)[:n]])\n",
    "                save_image(comparison.cpu(),\n",
    "                           SAVE_RESULTS + '/reconstruction_' + str(epoch) + sufix + '.png', nrow=n, normalize=True)\n",
    "\n",
    "    test_loss_mse = test_loss_mse * BATCH_SIZE / len(val_loader_celeba.dataset)\n",
    "    test_loss_kl = test_loss_kl * BATCH_SIZE / len(val_loader_celeba.dataset)\n",
    "    print('====> Test set loss-mse: {:.6f}, loss-kl: {:.6f}'.format(test_loss_mse, test_loss_kl))\n",
    "    val_losses.append((test_loss_mse, test_loss_kl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40520"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_loader_celeba.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/162078 (0%)]\tLoss MSE: 1.156556 \tLoss KL: 0.212160 \tTime Interv: 2.755783\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 314.00 MiB (GPU 0; 7.93 GiB total capacity; 5.62 GiB already allocated; 67.50 MiB free; 697.81 MiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-e776982a4242>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_on'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_off'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-a6509b5699bb>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mloss_mse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_kl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_custom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecon_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_mse\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss_kl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/portinari_pytorch/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \"\"\"\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/portinari_pytorch/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 314.00 MiB (GPU 0; 7.93 GiB total capacity; 5.62 GiB already allocated; 67.50 MiB free; 697.81 MiB cached)"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train(epoch)\n",
    "    test(epoch, '_on', True)\n",
    "    test(epoch, '_off', False)\n",
    "    model.train(False)\n",
    "    with torch.no_grad():\n",
    "        sample = torch.randn(BATCH_SIZE, BOTTLENECK_SIZE).to(device)\n",
    "        sample = model.decode(sample).cpu()\n",
    "        save_image(sample.view(BATCH_SIZE, 3, 200, 200),\n",
    "                   SAVE_RESULTS + '/sample_off_' + str(epoch) + '.png', normalize=True)\n",
    "    model.train(True)\n",
    "    with torch.no_grad():\n",
    "        sample = torch.randn(BATCH_SIZE, BOTTLENECK_SIZE).to(device)\n",
    "        sample = model.decode(sample).cpu()\n",
    "        save_image(sample.view(BATCH_SIZE, 3, 200, 200),\n",
    "                   SAVE_RESULTS + '/sample_on' + str(epoch) + '.png', normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.randn(BATCH_SIZE, BOTTLENECK_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.Tensor([[1,2,2,4]])\n",
    "x.exp().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_v = Variable(x.data.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.new(x.size()).normal_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.normal_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [train_loader_celeba.dataset[i][0].view(1,3,200,200) for i in range(100, 132)]\n",
    "'''img = img.view(1,3,200,200)\n",
    "data = img\n",
    "data.shape'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 34\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.cat(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(True)\n",
    "train_loss = 0\n",
    "\n",
    "data = data.to(device)\n",
    "optimizer.zero_grad()\n",
    "recon_batch, mu, logvar = model(data)\n",
    "loss_mse, loss_kl = loss_custom(recon_batch, data, mu, logvar)\n",
    "loss = loss_mse + loss_kl\n",
    "loss.backward()\n",
    "train_loss += loss.item()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_mse/32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dif = (recon_batch - data)\n",
    "dif.pow(2).sum()/(200*200*3*32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_kl/32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            }, SAVE_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample = 4\n",
    "sample_out1 = 5\n",
    "sample_out2 = 6\n",
    "sample = torch.randn(4, BOTTLENECK_SIZE).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_out1 = model.decode(sample).cpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 200, 200])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_out1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VAE_CNN(\n",
       "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (mxp1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (mxp2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (mxp3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (mxp4): MaxPool2d(kernel_size=2, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=43264, out_features=512, bias=True)\n",
       "  (fc_bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc2): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (fc_bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc3): Linear(in_features=512, out_features=43264, bias=True)\n",
       "  (fc_bn3): BatchNorm1d(43264, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (ups5): Upsample(scale_factor=2.0, mode=nearest)\n",
       "  (conv5): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (ups6): Upsample(scale_factor=2.0, mode=nearest)\n",
       "  (conv6): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (ups7): Upsample(scale_factor=2.0, mode=nearest)\n",
       "  (conv7): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (ups8): Upsample(scale_factor=2.0, mode=nearest)\n",
       "  (conv8): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn8): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv9): ConvTranspose2d(32, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu): ReLU()\n",
       "  (tanh): Tanh()\n",
       ")"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_out2 = model.decode(sample).cpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sample_out1-sample_out2).detach().numpy().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.train(True)\n",
    "sample = model.decode(sample).cpu()\n",
    "save_image(sample.view(BATCH_SIZE, 3, 200, 200),\n",
    "                   SAVE_RESULTS + '/sample_on_semnograd_' + str(epoch) + '.png', normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([0.9292, 0.8448, 0.9831, 1.0190, 0.9913, 0.9115, 0.9428, 1.0651, 0.8819,\n",
      "        0.9167, 1.1364, 1.1123, 1.1135, 1.0974, 0.9329, 1.0686, 0.9492, 0.9299,\n",
      "        1.1258, 1.1505, 1.1051, 0.9718, 1.0167, 0.9452, 1.1193, 1.0964, 0.8607,\n",
      "        0.9682, 1.1332, 1.0189, 0.9768, 1.1475], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0426, -0.1471, -0.0447,  0.0336,  0.0034, -0.1570,  0.0412,  0.1586,\n",
      "        -0.0386, -0.1243,  0.0757,  0.0099,  0.0115,  0.2145, -0.0811,  0.0070,\n",
      "        -0.0220, -0.0144,  0.2599,  0.2122,  0.0909, -0.0056,  0.0440,  0.0563,\n",
      "         0.1553,  0.2559,  0.0633,  0.0504,  0.0123,  0.2103, -0.0083,  0.1816],\n",
      "       device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for i in model.bn1.parameters():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''from torchvision.utils import make_grid\n",
    "import matplotlib.pyplot as plt'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''%matplotlib inline\n",
    "def show(img):\n",
    "    npimg = img.detach().numpy()\n",
    "    plt.figure(figsize=(30, 10))\n",
    "    plt.imshow(np.transpose(npimg, (1,2,0)), interpolation='nearest')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''model.train(True)\n",
    "test_loss = 0\n",
    "for i, (data, _) in enumerate(val_loader_celeba):\n",
    "    data = data.to(device)\n",
    "    recon_batch, mu, logvar = model(data)\n",
    "    loss_mse, loss_kl = loss_custom(recon_batch, data, mu, logvar)\n",
    "    loss = loss_mse + loss_kl\n",
    "    test_loss += loss.item()\n",
    "    if i == 0:\n",
    "        n = min(data.size(0), 8)\n",
    "        comparison = torch.cat([data[:n],\n",
    "                                recon_batch.view(7, 3, 200, 200)[:n]])\n",
    "        show(make_grid(comparison.cpu(), nrow=n, normalize=True))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''checkpoint = torch.load('model_save')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''model.train(True)\n",
    "test_loss = 0\n",
    "for i, (data, _) in enumerate(val_loader_celeba):\n",
    "    data = data.to(device)\n",
    "    recon_batch, mu, logvar = model(data)\n",
    "    loss_mse, loss_kl = loss_custom(recon_batch, data, mu, logvar)\n",
    "    loss = loss_mse + loss_kl\n",
    "    test_loss += loss.item()\n",
    "    if i == 0:\n",
    "        n = min(data.size(0), 8)\n",
    "        comparison = torch.cat([data[:n],\n",
    "                                recon_batch.view(7, 3, 200, 200)[:n]])\n",
    "        show(make_grid(comparison.cpu(), nrow=n, normalize=True))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''import random\n",
    "x_test = []\n",
    "plt.figure(figsize=(30,10))\n",
    "num_figs = 1\n",
    "plt.figure(figsize=(15,100))\n",
    "plt.axis('off')\n",
    "plt.imshow(make_grid(comparison.cpu(), nrow=n, normalize=True).detach().numpy())\n",
    "\n",
    "for i in range(num_figs):\n",
    "    figure_Decoded = vae_2.predict(np.array([x_test[i].astype('float32')/127.5 -1]), batch_size = b_size)\n",
    "    plt.axis('off')\n",
    "    plt.subplot(num_figs,2,1+i*2)\n",
    "    plt.imshow(x_test[i])\n",
    "    plt.axis('off')\n",
    "    plt.subplot(num_figs,2,2 + i*2)\n",
    "    plt.imshow((figure_Decoded[0]+1)/2)\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
